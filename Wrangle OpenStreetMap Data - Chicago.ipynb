{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>\n",
       "code_show=true; \n",
       "function code_toggle() {\n",
       " if (code_show){\n",
       " $('div.input').hide();\n",
       " } else {\n",
       " $('div.input').show();\n",
       " }\n",
       " code_show = !code_show\n",
       "} \n",
       "$( document ).ready(code_toggle);\n",
       "</script>\n",
       "<form action=\"javascript:code_toggle()\"><input type=\"submit\" value=\"Click here to toggle on/off the raw code.\"></form>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "HTML('''<script>\n",
    "code_show=true; \n",
    "function code_toggle() {\n",
    " if (code_show){\n",
    " $('div.input').hide();\n",
    " } else {\n",
    " $('div.input').show();\n",
    " }\n",
    " code_show = !code_show\n",
    "} \n",
    "$( document ).ready(code_toggle);\n",
    "</script>\n",
    "<form action=\"javascript:code_toggle()\"><input type=\"submit\" value=\"Click here to toggle on/off the raw code.\"></form>''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Andy Adamiec\n",
    "#### Data Wrangleing Curse - Udacity\n",
    "1/26/2017\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Project Overview\n",
    "\n",
    "The goal of this project was to use data munging techniques, such as assessing the quality of the data for validity, accuracy, completeness, consistency and uniformity, to clean the OpenStreetMap data for city of Chicago, IL. Once cleaned data is imported in to MongoDB database where further quries are issued to gain insight from this data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Project Objectives\n",
    "\n",
    "* Assess the quality of the data for validity, accuracy, completeness, consistency and uniformity.\n",
    "\n",
    "* Parse and gather data from popular file formats such as .csv, .json, .xml, and .html.\n",
    "\n",
    "* Process data from multiple files or very large files that can be cleaned programmatically.\n",
    "\n",
    "* Learn how to store, query, and aggregate data using MongoDB "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Data Set\n",
    "\n",
    "Data set used for this project is from OpenStreetMap for the city area of Chicago, IL and can be downloaded [here.](https://www.openstreetmap.org/relation/122604#map=10/41.8343/-87.7327)\n",
    "\n",
    "Data primitives for this data are nodes, ways, and relations.\n",
    "\n",
    "A **node** is one of the core elements in the OpenStreetMap data model. It consists of a single point in space defined by its latitude, longitude and node id.\n",
    "\n",
    "A **way** is an ordered list of nodes which normally also has at least one tag or is included within a Relation. A way can have between 2 and 2,000 nodes, although it's possible that faulty ways with zero or a single node exist. A way can be open or closed. A closed way is one whose last node on the way is also the first on that way. A closed way may be interpreted either as a closed polyline, or an area, or both.\n",
    "\n",
    "A **relation** is one of the core data elements that consists of one or more tags and also an ordered list of one or more nodes, ways and/or relations as members which is used to define logical or geographic relationships between other elements. A member of a relation can optionally have a role which describes the part that a particular feature plays within a relation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Problems Encountered in the Map\n",
    "\n",
    "* Abbreviated street types.\n",
    "\n",
    "* Incorrect zip codes with missing digits and state abbreviation in zip code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tag Type \n",
    "\n",
    "To better understand the data I have used count_tag.py code to get the higher-level tag counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Count number of tags in the file.\n",
    "\n",
    "import xml.etree.cElementTree as ET\n",
    "import pprint\n",
    "\n",
    "\n",
    "def count_tags(filename):\n",
    "    tags = {}\n",
    "    \n",
    "    for event, elem in ET.iterparse(filename,events=('start', 'end')):\n",
    "        if elem.tag in tags and event == 'start':\n",
    "            tags[elem.tag] += 1\n",
    "        elif event == 'start':\n",
    "            tags[elem.tag] = 1\n",
    "        elif event == 'end':\n",
    "            elem.clear()\n",
    "            \n",
    "    return tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bounds': 1,\n",
       " 'member': 100887,\n",
       " 'nd': 10539700,\n",
       " 'node': 8900098,\n",
       " 'osm': 1,\n",
       " 'relation': 4869,\n",
       " 'tag': 6877982,\n",
       " 'way': 1265560}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_tags('chicago_illinois.osm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will be focusing on **node** and **way** tags of this data and associated **tag** tags."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Auditing the k tags.\n",
    "\n",
    "We will first check \"k\" value for each \"tag\" and see if there are any potential problems. To do so we will first count the k tags in our data and look at the top 20 most frequent tags and then use three different regular expressions checking for following patterns: \n",
    "\n",
    "* \"lower\", for tags that contain only lowercase letters and are valid.\n",
    "* \"lower_colon\", for otherwise valid tags with a colon in their names.\n",
    "* \"problemchars\", for tags with problematic characters.\n",
    "* \"other\", for other tags that do not fall into the other three categories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Most frequent k tags in the data set.\n",
    "\n",
    "Lets look at the top 10 k tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def audit(osmfile):\n",
    "    tag_k = {}\n",
    "    osm_file = open(osmfile, \"r\")\n",
    "    for event, elem in ET.iterparse(osm_file, events=(\"start\",)):\n",
    "\n",
    "        if elem.tag == \"nodes\" or elem.tag == \"way\":\n",
    "            for tag in elem.iter(\"tag\"):\n",
    "                att = tag.attrib['k']\n",
    "                if att in tag_k:\n",
    "                    tag_k[att]+=1\n",
    "                else:\n",
    "                    tag_k[att] = 1\n",
    "\n",
    "    return tag_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import operator\n",
    "\n",
    "def sort_dict_val(d):\n",
    "    sorted_x = sorted(d.items(), key=operator.itemgetter(1))\n",
    "    sorted_x.reverse()\n",
    "    return sorted_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('building', 877653),\n",
       " ('chicago:building_id', 709050),\n",
       " ('addr:street', 487508),\n",
       " ('addr:housenumber', 484594),\n",
       " ('addr:street:name', 470573),\n",
       " ('addr:street:prefix', 466936),\n",
       " ('addr:street:type', 463807),\n",
       " ('building:levels', 421731),\n",
       " ('highway', 267502),\n",
       " ('name', 169861)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sort_dict_val(audit('chicago_illinois.osm'))[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can count how many tags fall with in each category [lower,lower_colon,other,problemchars]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from pprint import pprint\n",
    "\n",
    "lower = re.compile(r'^([a-z]|_)*$')\n",
    "lower_colon = re.compile(r'^([a-z]|_)*:([a-z]|_)*$')\n",
    "problemchars = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "\n",
    "\n",
    "def key_type(element, keys):\n",
    "    if element.tag == \"tag\":\n",
    "        \n",
    "        att = element.attrib['k'] \n",
    "        \n",
    "        m = lower.search(att)\n",
    "        o = problemchars.search(att)\n",
    "        n = lower_colon.search(att)\n",
    "        \n",
    "        if m:\n",
    "            keys['lower'] += 1\n",
    "        elif o:\n",
    "            keys['problemchars']+=1\n",
    "        elif n:\n",
    "            keys['lower_colon']+=1\n",
    "        else:\n",
    "            keys['other']+=1\n",
    "    return keys\n",
    "\n",
    "def process_map(filename):\n",
    "    keys = {\"lower\": 0, \"lower_colon\": 0, \"problemchars\": 0, \"other\": 0}\n",
    "    for _, element in ET.iterparse(filename):\n",
    "        keys = key_type(element, keys)\n",
    "\n",
    "    return keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lower': 2147804, 'lower_colon': 3134339, 'other': 1595839, 'problemchars': 0}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_map('chicago_illinois.osm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let take a look at the most frequent tags labeled as 'other'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_key_type(element, keys):\n",
    "    if element.tag == 'tag':\n",
    "        \n",
    "        att = element.attrib['k']\n",
    "        \n",
    "        m = lower.search(att)\n",
    "        o = problemchars.search(att)\n",
    "        n = lower_colon.search(att)\n",
    "        \n",
    "        if m:\n",
    "            if att in keys['lower']:\n",
    "                keys['lower'][att] += 1\n",
    "            else:\n",
    "                keys['lower'][att] = 1\n",
    "        elif o:\n",
    "            if att in keys['problemchars']:\n",
    "                keys['problemchars'][att] += 1\n",
    "            else:\n",
    "                keys['problemchars'][att] = 1\n",
    "        elif n:\n",
    "            if att in keys['lower_colon']:\n",
    "                keys['lower_colon'][att] += 1\n",
    "            else:\n",
    "                keys['lower_colon'][att] = 1\n",
    "        else:\n",
    "            if att in keys['other']:\n",
    "                keys['other'][att] += 1\n",
    "            else:\n",
    "                keys['other'][att] = 1\n",
    "    return keys\n",
    "\n",
    "\n",
    "def process_map(filename):\n",
    "    keys = {\"lower\": {}, \"lower_colon\": {}, \"problemchars\": {}, \"other\": {}}\n",
    "    for _, element in ET.iterparse(filename):\n",
    "        keys = count_key_type(element, keys)\n",
    "    return keys\n",
    "\n",
    "data = process_map('chicago_illinois.osm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('addr:street:name', 498511),\n",
       " ('addr:street:type', 492828),\n",
       " ('addr:street:prefix', 481555),\n",
       " ('tiger:name_base_1', 14654),\n",
       " ('name_1', 11617),\n",
       " ('tiger:name_type_1', 11311),\n",
       " ('NHD:FCode', 7637),\n",
       " ('NHD:ReachCode', 6627),\n",
       " ('NHD:ComID', 6584),\n",
       " ('tiger:name_direction_prefix_1', 5599)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sort_dict_val(data['other'])[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explore Users.\n",
    "\n",
    "Explore how many users contributed to the Chicago map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_user(element):\n",
    "    if element.tag == \"node\" or element.tag == \"way\" or element.tag == \"relation\":\n",
    "        uid = element.get('uid')\n",
    "        return uid\n",
    "\n",
    "\n",
    "def process_map(filename):\n",
    "    users = set()\n",
    "    for _, element in ET.iterparse(filename):\n",
    "        if get_user(element):\n",
    "            users.add(get_user(element))\n",
    "    return users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3098"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(process_map('chicago_illinois.osm'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exploring street names.\n",
    "\n",
    "We will audit street names to understand if there are any potential problems with the data. Lets first look at the sample of the street names in our data and then count the most frequent unexpected street types in the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "street_type_re = re.compile(r'\\b\\S+\\.?$', re.IGNORECASE)\n",
    "\n",
    "\n",
    "expected = [\"Street\", \"Avenue\", \"Boulevard\", \"Drive\", \"Court\", \"Place\", \"Square\", \"Lane\", \"Road\", \n",
    "            \"Trail\", \"Parkway\", \"Commons\"]\n",
    "\n",
    "def audit_street_type(street_types, street_name):\n",
    "    m = street_type_re.search(street_name)\n",
    "    if m:\n",
    "        street_type = m.group()\n",
    "        if street_type not in expected:\n",
    "            street_types[street_type].add(street_name)\n",
    "            \n",
    "def count_street_type(street_types_counts, street_name):\n",
    "    m = street_type_re.search(street_name)\n",
    "    if m:\n",
    "        street_type =m.group()\n",
    "        if street_type not in exprected:\n",
    "            if street_type in street_types_counts:\n",
    "                street_types_counts[street_type]+=1\n",
    "            else:\n",
    "                street_types_counts[street_type]=1 \n",
    "\n",
    "def is_street_name(elem):\n",
    "    return (elem.attrib['k'] == \"addr:street\")\n",
    "\n",
    "\n",
    "def audit(osmfile):\n",
    "    osm_file = open(osmfile, \"r\")\n",
    "    street_types = defaultdict(set)\n",
    "    street_types_counts={}\n",
    "    for event, elem in ET.iterparse(osm_file, events=(\"start\",)):\n",
    "\n",
    "        if elem.tag == \"node\" or elem.tag == \"way\":\n",
    "            for tag in elem.iter(\"tag\"):\n",
    "                if is_street_name(tag):\n",
    "                    audit_street_type(street_types, tag.attrib['v'])\n",
    "    osm_file.close()\n",
    "    return street_types\n",
    "\n",
    "data = audit('chicago_illinois.osm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'22': {'E Route 22', 'IL 22', 'Il 22'},\n",
       " '25': {'Larkin Ave #25'},\n",
       " '340': {'W Higgins Rd #340'},\n",
       " 'C405': {'S Williams St #C405'},\n",
       " 'Innovation': {'Innovation'},\n",
       " 'RD': {'Randall RD'},\n",
       " 'Suite': {'Sherman Avenue Suite'},\n",
       " 'avenue': {'Colombia avenue'}}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{k: data[k] for k in list(data)[2:10]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most frequent unexpected street types in the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "street_type_re = re.compile(r'\\b\\S+\\.?$', re.IGNORECASE)\n",
    "\n",
    "\n",
    "expected = [\"Street\", \"Avenue\", \"Boulevard\", \"Drive\", \"Court\", \"Place\", \"Square\", \"Lane\", \"Road\", \n",
    "            \"Trail\", \"Parkway\", \"Commons\"]\n",
    "\n",
    "\n",
    "\n",
    "def count_street_type(street_types_counts, street_name):\n",
    "    m = street_type_re.search(street_name)\n",
    "    if m:\n",
    "        street_type =m.group()\n",
    "        if street_type not in expected:\n",
    "            if street_type in street_types_counts:\n",
    "                street_types_counts[street_type]+=1\n",
    "            else:\n",
    "                street_types_counts[street_type]=1 \n",
    "\n",
    "def is_street_name(elem):\n",
    "    return (elem.attrib['k'] == \"addr:street\")\n",
    "\n",
    "\n",
    "def audit(osmfile):\n",
    "    osm_file = open(osmfile, \"r\")\n",
    "    street_types = defaultdict(set)\n",
    "    street_types_counts={}\n",
    "    for event, elem in ET.iterparse(osm_file, events=(\"start\",)):\n",
    "\n",
    "        if elem.tag == \"node\" or elem.tag == \"way\":\n",
    "            for tag in elem.iter(\"tag\"):\n",
    "                if is_street_name(tag):\n",
    "                    count_street_type(street_types, tag.attrib['v'])\n",
    "    osm_file.close()\n",
    "    return street_types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def count_street_type(street_types_counts, street_name):\n",
    "    m = street_type_re.search(street_name)\n",
    "    if m:\n",
    "        street_type =m.group()\n",
    "        if street_type not in expected:\n",
    "            if street_type in street_types_counts:\n",
    "                street_types_counts[street_type]+=1\n",
    "            else:\n",
    "                street_types_counts[street_type]=1 \n",
    "\n",
    "def is_street_name(elem):\n",
    "    return (elem.attrib['k'] == \"addr:street\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('M', 712),\n",
       " ('N', 627),\n",
       " ('Dr', 627),\n",
       " ('Terrace', 559),\n",
       " ('J', 554),\n",
       " ('O', 509),\n",
       " ('H', 490),\n",
       " ('Highway', 444),\n",
       " ('G', 414)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sort_dict_val(audit('chicago_illinois.osm'))[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice few extra types which do not have any issues but are not in our expected list like: [Terrace,Broadway,Highway,Circle,Park,Plaza,Way,West].These will be added to the expected list. \n",
    "\n",
    "Some of the issues are as follows: [Ave,Pkwy,Dr,St,Ct,Rd.,Cir]. These will be added to the mapping file for correction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imroving Street Names\n",
    "\n",
    "Now we can fix the error we found in the street names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import xml.etree.cElementTree as ET\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import pprint\n",
    "\n",
    "OSMFILE = \"chicago_illinois.osm\"\n",
    "street_type_re = re.compile(r'\\b\\S+\\.?$', re.IGNORECASE)\n",
    "\n",
    "\n",
    "expected = [\"Street\", \"Avenue\", \"Boulevard\", \"Drive\", \"Court\", \"Place\", \"Square\", \"Lane\", \"Road\", \n",
    "            \"Trail\", \"Parkway\", \"Commons\",'Terrace','Broadway','Highway','Circle','Park','Plaza','Way','West']\n",
    "\n",
    "mapping = { \"St\": \"Street\",\n",
    "            \"St.\": \"Street\",\n",
    "            \"Ave\": \"Avenue\",\n",
    "            \"Rd.\":\"Road\",\n",
    "            \"Cir\": \"Circle\",\n",
    "            \"Pkwy\":\"Parkway\",\n",
    "            \"Dr\":\"Drive\",\n",
    "            \"Ct\": \"Court\"\n",
    "            }\n",
    "\n",
    "\n",
    "def audit_street_type(street_types, street_name):\n",
    "    m = street_type_re.search(street_name)\n",
    "    if m:\n",
    "        street_type = m.group()\n",
    "        if street_type not in expected and street_type in mapping:\n",
    "            street_types[street_type].add(street_name)\n",
    "\n",
    "\n",
    "def is_street_name(elem):\n",
    "    return (elem.attrib['k'] == \"addr:street\")\n",
    "\n",
    "\n",
    "def audit(osmfile):\n",
    "    osm_file = open(osmfile, \"r\")\n",
    "    street_types = defaultdict(set)\n",
    "    for event, elem in ET.iterparse(osm_file, events=(\"start\",)):\n",
    "\n",
    "        if elem.tag == \"node\" or elem.tag == \"way\":\n",
    "            for tag in elem.iter(\"tag\"):\n",
    "                if is_street_name(tag):\n",
    "                    audit_street_type(street_types, tag.attrib['v'])\n",
    "    osm_file.close()\n",
    "    return street_types\n",
    "\n",
    "\n",
    "def update_name(name, mapping):\n",
    "    m = street_type_re.search(name)\n",
    "    street_type = m.group()\n",
    "    mapping[street_type]\n",
    "    return name.replace(street_type, mapping[street_type])\n",
    "\n",
    "\n",
    "def test():\n",
    "    st_types = audit(OSMFILE)\n",
    "    name_list = []\n",
    "    for st_type, ways in st_types.iteritems():\n",
    "        for name in ways:\n",
    "            better_name = update_name(name, mapping)\n",
    "            name_list.append(name+\" => \"+better_name)\n",
    "    return name_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def is_street_name(elem):\n",
    "    return (elem.attrib['k'] == \"addr:street\")\n",
    "\n",
    "\n",
    "def audit(osmfile):\n",
    "    osm_file = open(osmfile, \"r\")\n",
    "    street_types = defaultdict(set)\n",
    "    for event, elem in ET.iterparse(osm_file, events=(\"start\",)):\n",
    "\n",
    "        if elem.tag == \"node\" or elem.tag == \"way\":\n",
    "            for tag in elem.iter(\"tag\"):\n",
    "                if is_street_name(tag):\n",
    "                    audit_street_type(street_types, tag.attrib['v'])\n",
    "    osm_file.close()\n",
    "    return street_types\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['W. State Rd. => W. State Road',\n",
       " 'N. Rand Rd. => N. Rand Road',\n",
       " 'S Elmhurst Rd. => S Elmhurst Road',\n",
       " 'St. Charles Rd. => St. Charles Road',\n",
       " 'E. Rand Rd. => E. Rand Road',\n",
       " 'E. Boughton Rd. => E. Boughton Road',\n",
       " 'N. Wolf Rd. => N. Wolf Road',\n",
       " 'Oakton St. => Oakton Street',\n",
       " 'W. Lake St. => W. Lake Street']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[1:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The output data looks good, the errors within the street names where fixed successfully."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets audit postal codes in the data to see if there are any errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "zipcode_re = re.compile(r'^\\d{5}(?:[-\\s]?\\d{4})?$', re.IGNORECASE)\n",
    "\n",
    "\n",
    "def audit_zip_code(zip_code_types, zip_code):\n",
    "    m = zipcode_re.search(zip_code)\n",
    "    if not m:\n",
    "        zip_code_types[zip_code].add(zip_code)\n",
    "\n",
    "\n",
    "def is_zip_code(elem):\n",
    "    return (elem.attrib['k'] == \"addr:postcode\")\n",
    "\n",
    "\n",
    "def audit_zip(osmfile):\n",
    "    osm_file = open(osmfile, \"r\")\n",
    "    zip_code_types = defaultdict(set)\n",
    "    for event, elem in ET.iterparse(osm_file, events=(\"start\",)):\n",
    "\n",
    "        if elem.tag == \"node\" or elem.tag == \"way\":\n",
    "            for tag in elem.iter(\"tag\"):\n",
    "                if is_zip_code(tag):\n",
    "                    audit_zip_code(zip_code_types, tag.attrib['v'])\n",
    "    osm_file.close()\n",
    "    return zip_code_types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "zipcode_re = re.compile(r'^\\d{5}(?:[-\\s]?\\d{4})?$', re.IGNORECASE)\n",
    "\n",
    "\n",
    "def audit_zip_code(zip_code_types, zip_code):\n",
    "    m = zipcode_re.search(zip_code)\n",
    "    if not m:\n",
    "        zip_code_types[zip_code].add(zip_code)\n",
    "\n",
    "\n",
    "def is_zip_code(elem):\n",
    "    return (elem.attrib['k'] == \"addr:postcode\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Il', {'Il'}),\n",
       " ('6074', {'6074'}),\n",
       " ('IL, 60642', {'IL, 60642'}),\n",
       " ('6017', {'6017'}),\n",
       " ('IL 60118', {'IL 60118'}),\n",
       " ('Wasco, IL 60183', {'Wasco, IL 60183'}),\n",
       " ('606226', {'606226'}),\n",
       " ('690639', {'690639'}),\n",
       " ('IL 60707', {'IL 60707'})]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sort_dict_val(audit_zip(\"chicago_illinois.osm\"))[1:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the most part zip code are clean in our data. The above error are few compare to the size of data and I will replace them with a NULL value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are ready to save the data in JSON format and read it in to MongoDB data base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import xml.etree.cElementTree as ET\n",
    "import pprint\n",
    "import re\n",
    "import codecs\n",
    "import json\n",
    "\n",
    "street_type_re = re.compile(r'\\b\\S+\\.?$', re.IGNORECASE)\n",
    "zipcode_re = re.compile(r'^\\d{5}(?:[-\\s]?\\d{4})?$', re.IGNORECASE)\n",
    "\n",
    "mapping = { \"St\": \"Street\",\n",
    "            \"St.\": \"Street\",\n",
    "            \"Ave\": \"Avenue\",\n",
    "            \"Rd.\":\"Road\",\n",
    "            \"Cir\": \"Circle\",\n",
    "            \"Pkwy\":\"Parkway\",\n",
    "            \"Dr\":\"Drive\",\n",
    "            \"Ct\": \"Court\"}\n",
    "\n",
    "def update_name(name, mapping):\n",
    "    m = street_type_re.search(name)\n",
    "    if m:\n",
    "        street_type = m.group()\n",
    "        if street_type in mapping:\n",
    "            return name.replace(street_type, mapping[street_type])\n",
    "        else:\n",
    "            return name\n",
    "    \n",
    "def update_zip(zip_code):\n",
    "    m = zipcode_re.search(zip_code)\n",
    "    if m:\n",
    "        return zip_code\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "lower = re.compile(r'^([a-z]|_)*$')\n",
    "lower_colon = re.compile(r'^([a-z]|_)*:([a-z]|_)*$')\n",
    "problemchars = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "\n",
    "CREATED = [ \"version\", \"changeset\", \"timestamp\", \"user\", \"uid\"]\n",
    "\n",
    "\n",
    "\n",
    "def shape_element(element):\n",
    "    node = {}\n",
    "    \n",
    "    if element.tag == \"node\" or element.tag == \"way\":\n",
    "        \n",
    "        address_dic = {}\n",
    "        nd_list = []\n",
    "        \n",
    "        for tag in element.iter(\"tag\"):\n",
    "            \n",
    "            att = tag.attrib['k'] \n",
    "        \n",
    "            if problemchars.search(att):\n",
    "                continue\n",
    "                \n",
    "            elif tag.attrib['k'].startswith(\"addr:\") and len(tag.attrib['k'].split(':')) < 3:\n",
    "                \n",
    "                if att.find('street')>-1:\n",
    "                    address_dic['street']=update_name(tag.attrib['v'],mapping)\n",
    "                    \n",
    "                elif att.find('housenumber')>-1:\n",
    "                    address_dic['housenumber']=tag.attrib['v']\n",
    "                    \n",
    "                elif att.find('postcode')>-1:\n",
    "                    address_dic['postcode']=update_zip(tag.attrib['v'])\n",
    "                    \n",
    "            elif not tag.attrib['k'].startswith(\"addr:\") and len(tag.attrib['k'].split(':')) < 3:\n",
    "                temp_list = tag.attrib['k'].split(':')\n",
    "                node[temp_list[-1]] = tag.attrib['v']\n",
    " \n",
    "        if bool(address_dic):        \n",
    "            node['address']  = address_dic    \n",
    "\n",
    "        node['type'] = element.tag\n",
    "        \n",
    "        for tag in element.iter('nd'):\n",
    "            nd_list.append(tag.attrib['ref'])\n",
    "        \n",
    "        if len(nd_list) > 0:\n",
    "            node['node_refs'] = nd_list \n",
    "            \n",
    "        created_dic = {}            \n",
    "        pos_list = [None,None]\n",
    "        \n",
    "        for key,val in element.items():\n",
    "            \n",
    "            if key == 'lat':\n",
    "                pos_list[0] = float(val)\n",
    "            elif key == 'lon':\n",
    "                pos_list[1] = float(val)\n",
    "            elif key in CREATED:\n",
    "                created_dic[key] = val\n",
    "            else:\n",
    "                node[key] = val\n",
    "            \n",
    "        node['created'] = created_dic\n",
    "        node['pos'] = pos_list\n",
    "        \n",
    "        return node\n",
    "    else:\n",
    "        return None    \n",
    "\n",
    "\n",
    "def process_map(file_in, pretty = False):\n",
    "    # You do not need to change this file\n",
    "    file_out = \"{0}.json\".format(file_in)\n",
    "    data = []\n",
    "    with codecs.open(file_out, \"w\") as fo:\n",
    "        for _, element in ET.iterparse(file_in):\n",
    "            el = shape_element(element)\n",
    "            if el:\n",
    "                data.append(el)\n",
    "                if pretty:\n",
    "                    fo.write(json.dumps(el, indent=2)+\"\\n\")\n",
    "                else:\n",
    "                    fo.write(json.dumps(el) + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "process_map('chicago_illinois.osm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "\n",
    "def shape_element(element):\n",
    "    node = {}\n",
    "    \n",
    "    if element.tag == \"node\" or element.tag == \"way\":\n",
    "        \n",
    "        address_dic = {}\n",
    "        nd_list = []\n",
    "        \n",
    "        for tag in element.iter(\"tag\"):\n",
    "            \n",
    "            att = tag.attrib['k'] \n",
    "        \n",
    "            if problemchars.search(att):\n",
    "                continue\n",
    "                \n",
    "            elif tag.attrib['k'].startswith(\"addr:\") and len(tag.attrib['k'].split(':')) < 3:\n",
    "                \n",
    "                if att.find('street')>-1:\n",
    "                    address_dic['street']=update_name(tag.attrib['v'],mapping)\n",
    "                    \n",
    "                elif att.find('housenumber')>-1:\n",
    "                    address_dic['housenumber']=tag.attrib['v']\n",
    "                    \n",
    "                elif att.find('postcode')>-1:\n",
    "                    address_dic['postcode']=update_zip(tag.attrib['v'])\n",
    "                    \n",
    "            elif not tag.attrib['k'].startswith(\"addr:\") and len(tag.attrib['k'].split(':')) < 3:\n",
    "                temp_list = tag.attrib['k'].split(':')\n",
    "                node[temp_list[-1]] = tag.attrib['v']\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data in to MongoDB data-base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "\n",
    "client = MongoClient('localhost', 27017)\n",
    "db = client.osm\n",
    "collection = db.chicago\n",
    "\n",
    "collection.drop()\n",
    "os.system('mongoimport -d osm -c chicago chicago_illinois.osm.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "File size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chicago OSM file is 2123.531129 MB\n"
     ]
    }
   ],
   "source": [
    "print 'Chicago OSM file is {} MB'.format(os.path.getsize('chicago_illinois.osm')/1.0e6) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10165658"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.chicago.find().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of unique users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3069"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(db.chicago.distinct('created.user'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8900098"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.chicago.find({\"type\":\"node\"}).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of ways."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1265560"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.chicago.find({\"type\":\"way\"}).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most popular cuisine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'count': 198, u'_id': u'pizza'}\n",
      "{u'count': 180, u'_id': u'mexican'}\n",
      "{u'count': 136, u'_id': u'american'}\n",
      "{u'count': 91, u'_id': u'italian'}\n",
      "{u'count': 81, u'_id': u'burger'}\n",
      "{u'count': 75, u'_id': u'chinese'}\n",
      "{u'count': 54, u'_id': u'sandwich'}\n",
      "{u'count': 43, u'_id': u'thai'}\n",
      "{u'count': 34, u'_id': u'japanese'}\n",
      "{u'count': 28, u'_id': u'indian'}\n",
      "{u'count': 25, u'_id': u'sushi'}\n",
      "{u'count': 24, u'_id': u'steak_house'}\n",
      "{u'count': 23, u'_id': u'breakfast'}\n",
      "{u'count': 22, u'_id': u'barbecue'}\n",
      "{u'count': 21, u'_id': u'chicken'}\n",
      "{u'count': 16, u'_id': u'greek'}\n",
      "{u'count': 14, u'_id': u'asian'}\n",
      "{u'count': 13, u'_id': u'ice_cream'}\n",
      "{u'count': 13, u'_id': u'regional'}\n",
      "{u'count': 11, u'_id': u'french'}\n"
     ]
    }
   ],
   "source": [
    "pipeline = [{\"$match\":{\"amenity\":{\"$exists\":1}, \"amenity\":\"restaurant\", \"cuisine\":{\"$exists\":1}}}, \n",
    "            {\"$group\":{\"_id\":\"$cuisine\", \"count\":{\"$sum\":1}}},        \n",
    "            {\"$sort\":{\"count\":-1}}, \n",
    "            {\"$limit\":20}]\n",
    "result = db.chicago.aggregate(pipeline)\n",
    "\n",
    "for pp in list(result):\n",
    "    print(pp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most frequant zip code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'count': 9395, u'_id': u'60201'}\n",
      "{u'count': 7620, u'_id': u'60202'}\n",
      "{u'count': 1724, u'_id': u'60305'}\n",
      "{u'count': 1685, u'_id': u'60564'}\n",
      "{u'count': 1306, u'_id': u'60136'}\n",
      "{u'count': 1259, u'_id': u'60042'}\n",
      "{u'count': 909, u'_id': u'60637'}\n",
      "{u'count': 868, u'_id': u'60089'}\n",
      "{u'count': 657, u'_id': u'60148'}\n",
      "{u'count': 536, u'_id': u'60565'}\n"
     ]
    }
   ],
   "source": [
    "zip_code = db.chicago.aggregate( [ \n",
    "    { \"$match\" : { \"address.postcode\" : { \"$exists\" : 1} } }, \n",
    "    { \"$group\" : { \"_id\" : \"$address.postcode\", \"count\" : { \"$sum\" : 1} } },  \n",
    "    { \"$sort\" : { \"count\" : -1}},\n",
    "      {\"$limit\":10}] )\n",
    "\n",
    "\n",
    "for pp in list(zip_code):\n",
    "    print(pp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most frequent amenities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'count': 14240, u'_id': u'parking'}\n",
      "{u'count': 4410, u'_id': u'place_of_worship'}\n",
      "{u'count': 3432, u'_id': u'school'}\n",
      "{u'count': 2522, u'_id': u'restaurant'}\n",
      "{u'count': 1636, u'_id': u'fast_food'}\n",
      "{u'count': 1147, u'_id': u'fuel'}\n",
      "{u'count': 761, u'_id': u'bank'}\n",
      "{u'count': 638, u'_id': u'bench'}\n",
      "{u'count': 567, u'_id': u'cafe'}\n",
      "{u'count': 548, u'_id': u'shelter'}\n"
     ]
    }
   ],
   "source": [
    "amenity_count = db.chicago.aggregate( [ \n",
    "    { \"$match\" : { \"amenity\" : { \"$exists\" : 1} } }, \n",
    "    { \"$group\" : { \"_id\" : \"$amenity\", \"count\" : { \"$sum\" : 1} } },  \n",
    "    { \"$sort\" : { \"count\" : -1}},\n",
    "      {\"$limit\":10}] )\n",
    "\n",
    "\n",
    "for pp in list(amenity_count):\n",
    "    print(pp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most popular cuisine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'count': 603, u'_id': u'burger'}\n",
      "{u'count': 276, u'_id': u'mexican'}\n",
      "{u'count': 260, u'_id': u'pizza'}\n",
      "{u'count': 215, u'_id': u'sandwich'}\n",
      "{u'count': 179, u'_id': u'coffee_shop'}\n",
      "{u'count': 171, u'_id': u'american'}\n",
      "{u'count': 107, u'_id': u'chicken'}\n",
      "{u'count': 98, u'_id': u'chinese'}\n",
      "{u'count': 97, u'_id': u'italian'}\n",
      "{u'count': 52, u'_id': u'ice_cream'}\n"
     ]
    }
   ],
   "source": [
    "cuisine_count = db.chicago.aggregate( [ \n",
    "    { \"$match\" : { \"cuisine\" : { \"$exists\" : 1} } }, \n",
    "    { \"$group\" : { \"_id\" : \"$cuisine\", \"count\" : { \"$sum\" : 1} } },  \n",
    "    { \"$sort\" : { \"count\" : -1}},\n",
    "      {\"$limit\":10}] )\n",
    "\n",
    "\n",
    "for pp in list(cuisine_count):\n",
    "    print(pp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Additional Suggestion and Ideas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "One possible improvement which can be beneficial is grouping tags into higher level categories.  Some tags are very similar to each other for example there are several tags which can be though of as restaurants but are labeled as ‘cafe’, ‘food_court’,’bar’ etc.  I would also add a higher level tag for business and government building such tags would increase speed in which one can relative data from data base."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
